<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width,initial-scale=1">
  <title>Live Interview ‚Äî IntervYou</title>

  <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">

  <style>
    .layout {
      display: grid;
      grid-template-columns: 1.2fr 1fr;
      gap: 30px;
      align-items: start;
    }
    #videoElem {
      width: 100%;
      border-radius: 12px;
      background:black;
    }
    .hr-photo {
      width:140px;
      height:140px;
      border-radius:50%;
      object-fit:cover;
      box-shadow:0 4px 12px rgba(0,0,0,0.2);
    }
    .question-box {
      padding:15px;
      background:#f5f8ff;
      border-radius:8px;
      margin-bottom:12px;
      font-size:17px;
    }
    .transcript-box {
      background:white;
      padding:10px;
      border-radius:8px;
      height:150px;
      overflow-y:auto;
      border:1px solid #ddd;
      font-size:15px;
    }
    .hidden { display:none; }
  </style>
</head>

<body class="upload-page">

<div style="text-align:center; margin-bottom:20px;">
  <img src="{{ url_for('static', filename='images/logo/interyou.png') }}" style="height:70px;">
</div>

<div class="page-card wide">

  <h1 style="text-align:center; margin-bottom:25px;">üéØ Live AI Interview</h1>

  <div class="layout">

    <!-- LEFT SIDE : USER CAMERA -->
    <div>
      <video id="videoElem" autoplay muted playsinline></video>

      <div style="margin-top:12px;">
        <button id="enableMedia" class="btn">Enable Camera & Mic</button>
        <button id="stopMedia" class="btn outline" disabled>Stop</button>
        <div id="mediaStatus" class="muted" style="margin-top:6px;">Camera is off.</div>
      </div>
    </div>

    <!-- RIGHT SIDE : HR + INTERVIEW -->
    <div>

      <div style="text-align:center;">
        <img src="{{ url_for('static', filename='images/avatar/hr_idle.png') }}" id="hrAvatar" class="hr-photo">
        <div class="muted">Virtual HR ‚Äî Mr. James</div>
      </div>

      <div id="qPanel" class="hidden">

        <div id="questionText" class="question-box">
          Press ‚ÄúStart Interview‚Äù to begin.
        </div>

        <div style="display:flex; gap:10px; margin-bottom:8px;">
          <button id="startInterview" class="btn">Start</button>
          <button id="recordBtn" class="btn" disabled>üéô Record</button>
          <button id="stopRec" class="btn outline" disabled>‚ñ† Stop</button>
          <button id="nextQ" class="btn outline" disabled>Next ‚Üí</button>
        </div>

        <div class="muted">Question <span id="qIndex">0</span> / <span id="qTotal">0</span></div>

        <h3 style="margin-top:15px;">Transcript</h3>
        <div id="transcript" class="transcript-box">‚Äî</div>

        <h3 style="margin-top:15px;">AI Feedback</h3>
        <div id="analysis" class="transcript-box">‚Äî</div>

      </div>

    </div>

  </div>

</div>

<!-- =============================== -->
<!--          JAVASCRIPT            -->
<!-- =============================== -->
<script>
/* -----------------------------------------------------------
   DATA FROM SERVER
----------------------------------------------------------- */
const questions = {{ questions|tojson }} || [];
let qIndex = 0;

let mediaStream = null;
let mediaRecorder = null;
let recordedChunks = [];

let isRecording = false;
let recognition = null;
let recognitionAvailable = false;

let collectedTranscript = [];

let synth = window.speechSynthesis;

/* -----------------------------------------------------------
   ELEMENTS
----------------------------------------------------------- */
const enableBtn = document.getElementById("enableMedia");
const stopBtn   = document.getElementById("stopMedia");
const videoElem = document.getElementById("videoElem");
const hrAvatar  = document.getElementById("hrAvatar");

const startBtn  = document.getElementById("startInterview");
const recordBtn = document.getElementById("recordBtn");
const stopRecBtn= document.getElementById("stopRec");
const nextBtn   = document.getElementById("nextQ");

const qPanel     = document.getElementById("qPanel");
const questionBox= document.getElementById("questionText");
const transcriptBox = document.getElementById("transcript");
const qIndexHTML = document.getElementById("qIndex");
const qTotalHTML = document.getElementById("qTotal");
const mediaStatus = document.getElementById("mediaStatus");

qTotalHTML.textContent = questions.length;

/* -----------------------------------------------------------
   UTILITY: Safe HTML
----------------------------------------------------------- */
function escapeHtml(unsafe) {
  return unsafe.replace(/[&<>"']/g,function(m){
    return ({'&':'&amp;','<':'&lt;','>':'&gt;','"':'&quot;',"'":'&#039;'}[m]);
  });
}

/* -----------------------------------------------------------
   APPEND TRANSCRIPT
----------------------------------------------------------- */
function appendTranscript(entry){
  if(!entry || !entry.text) return;
  const last = collectedTranscript[collectedTranscript.length-1];

  if(last && last.speaker === entry.speaker && last.text === entry.text) return;

  collectedTranscript.push(entry);

  const p = document.createElement("p");
  p.innerHTML = `<b>${entry.speaker}:</b> ${escapeHtml(entry.text)}`;
  transcriptBox.appendChild(p);
  transcriptBox.scrollTop = transcriptBox.scrollHeight;
}

/* -----------------------------------------------------------
   CAMERA ENABLE
----------------------------------------------------------- */
enableBtn.onclick = async () => {
  try {
    mediaStream = await navigator.mediaDevices.getUserMedia({ video:true, audio:true });
    videoElem.srcObject = mediaStream;

    enableBtn.disabled = true;
    stopBtn.disabled = false;
    recordBtn.disabled = false;
    qPanel.classList.remove("hidden");
    mediaStatus.textContent = "Camera & mic ready.";
  } catch (e) {
    alert("Please allow camera and microphone access.");
  }
};

/* -----------------------------------------------------------
   STOP CAMERA
----------------------------------------------------------- */
stopBtn.onclick = () => {
  if (mediaStream){
    mediaStream.getTracks().forEach(t => t.stop());
    mediaStream = null;
  }
  videoElem.srcObject = null;

  enableBtn.disabled = false;
  stopBtn.disabled = true;
  recordBtn.disabled = true;
  stopRecBtn.disabled = true;

  mediaStatus.textContent = "Camera stopped.";
};

/* -----------------------------------------------------------
   HR SPEECH
----------------------------------------------------------- */
function speak(text){
  return new Promise(res=>{
    hrAvatar.src="{{ url_for('static', filename='images/avatar/hr_talking.gif') }}";

    const u = new SpeechSynthesisUtterance(text);
    u.onend = () => {
      hrAvatar.src="{{ url_for('static', filename='images/avatar/hr_idle.png') }}";
      setTimeout(res, 200);
    };

    synth.speak(u);
  });
}

/* -----------------------------------------------------------
   SHOW QUESTION
----------------------------------------------------------- */
function showQuestion(i, text){
  questionBox.textContent = text;
  qIndexHTML.textContent = i+1;
  appendTranscript({speaker:"HR", text:text});
}

/* -----------------------------------------------------------
   INIT SPEECH RECOGNITION
----------------------------------------------------------- */
if (window.SpeechRecognition || window.webkitSpeechRecognition){
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  recognition = new SR();
  recognition.lang = "en-US";
  recognition.continuous = false;
  recognition.interimResults = false;

  recognition.onresult = e => {
    try {
      const text = e.results[0][0].transcript.trim();
      appendTranscript({speaker:"User", text});
    } catch {}
  };

  recognition.onerror = ()=>{};
  recognitionAvailable = true;
}

/* -----------------------------------------------------------
   RECORDING
----------------------------------------------------------- */
async function startRecording(){
  if(!mediaStream){
    alert("Enable camera & mic first.");
    return;
  }

  if(isRecording) return;

  recordedChunks = [];
  mediaRecorder = new MediaRecorder(mediaStream);
  
  mediaRecorder.ondataavailable = e => {
    if(e.data.size > 0) recordedChunks.push(e.data);
  };

  mediaRecorder.onstop = uploadClip;

  mediaRecorder.start();
  isRecording = true;

  recordBtn.disabled = true;
  stopRecBtn.disabled = false;

  if(recognitionAvailable){
    setTimeout(() => {
      try { recognition.start(); } catch {}
    }, 350);
  }
}

function stopRecording(){
  if(!isRecording) return;

  try { recognition.stop(); } catch {}
  try { mediaRecorder.stop(); } catch {}

  isRecording = false;
  stopRecBtn.disabled = true;
  recordBtn.disabled = false;
}

recordBtn.onclick = startRecording;
stopRecBtn.onclick = stopRecording;

/* -----------------------------------------------------------
   CLIP UPLOAD
----------------------------------------------------------- */
async function uploadClip(){
  if(!recordedChunks.length) return;

  const blob = new Blob(recordedChunks,{type:"video/webm"});
  const fd = new FormData();

  fd.append("clip", blob, `q${qIndex+1}.webm`);
  fd.append("qindex", String(qIndex+1));
  fd.append("question_text", questions[qIndex].question_text);

  mediaStatus.textContent = "Uploading clip...";

  try{
    await fetch("/upload_clip", { method:"POST", body:fd });
    mediaStatus.textContent = "Clip uploaded.";
  } catch {
    mediaStatus.textContent = "Upload failed.";
  }

  setTimeout(() => mediaStatus.textContent = "Camera & mic ready.", 800);
}

/* -----------------------------------------------------------
   START INTERVIEW
----------------------------------------------------------- */
startBtn.onclick = async () => {
  startBtn.disabled = true;
  nextBtn.disabled = false;

  transcriptBox.innerHTML = "";
  collectedTranscript = [];

  const intro = "Hello, I am Mr. James, your virtual HR. Please answer naturally.";
  appendTranscript({speaker:"HR", text:intro});
  await speak(intro);

  qIndex = 0;
  const qtext = questions[0].question_text;
  showQuestion(0, qtext);
  await speak(qtext);
};

/* -----------------------------------------------------------
   END MESSAGE ON INTERVIEW FINISH
----------------------------------------------------------- */
async function speakEndMessage(){
  const msg = "Thank you. Your interview has ended.";
  appendTranscript({speaker:"HR", text:msg});
  await speak(msg);
}

/* -----------------------------------------------------------
   NEXT QUESTION
----------------------------------------------------------- */
nextBtn.onclick = async () => {
  if(isRecording) stopRecording();

  qIndex++;

  if(qIndex >= questions.length){

    await speakEndMessage();

    await fetch("/save_transcript",{
      method:"POST",
      headers:{"Content-Type":"application/json"},
      body:JSON.stringify({ transcript: collectedTranscript })
    });

    await fetch("/feedback_analysis",{ method:"POST" });

    window.location.href="/feedback";
    return;
  }

  const qtext = questions[qIndex].question_text;
  showQuestion(qIndex, qtext);
  await speak(qtext);
};

</script>

</body>
</html>
